dGP is defined to be the amount of games played in the target year above the average number of games played in the previous four seasons. Null values are omitted and not treated as 0. Making dGP the target variable instead of GP improved model accuracy.

For some reason, the earlier models (model 1, epoch 1 standardscaler specifically) tends to over-regress results while maintaining a decent MAE. Investigate this.

Be careful when considering features other than age, height, weight. Make sure to index 'statline' correctly so that the subset of the list represents the target/dependent variable. This applies in the for index, statline in enumerate() loop in preprocessing_training_functions.py.

!! Add a neural network architecture/hyperparameter catalog CSV file / Turn the storage of model architectures/hyperparameters into a CSV (currently commented in model_analysis.py)
--> Also another document briefing the differences between each NN projector for the different stats (filters, features, etc.)

Consider using cross-validation for model testing?
Consider Bayesian neural network for uncertainty?
Random forest?
